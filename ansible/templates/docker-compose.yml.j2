services:
  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: cloudflared
    restart: always
    user: "{{ apps_uid }}:{{ apps_gid }}"
    command: tunnel run
    environment:
      - TUNNEL_TOKEN=${CLOUDFLARED_TUNNEL_TOKEN}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - ghostship_net

  muximux:
    image: lscr.io/linuxserver/muximux:latest
    container_name: muximux
    restart: always
    environment:
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
      - TZ=UTC
    volumes:
      - ${CONFIG_DIR}/muximux:/config
    networks:
      - ghostship_net

  gluetun:
    image: qmcgaw/gluetun:latest
    container_name: gluetun
    user: "0:0"
    cap_add:
      - NET_ADMIN
    devices:
      - /dev/net/tun:/dev/net/tun
    environment:
      - VPN_SERVICE_PROVIDER=private internet access
      - SERVER_REGIONS=${VPN_PIA_REGION}
      - OPENVPN_USER=${VPN_PIA_USER}
      - OPENVPN_PASSWORD=${VPN_PIA_PASS}
      - VPN_PORT_FORWARDING=on
      - VPN_PORT_FORWARDING_UP_COMMAND=/bin/sh -c 'wget -O- --retry-connrefused --post-data "json={\"listen_port\":{{ '{{' }}PORT{{ '}}' }},\"current_network_interface\":\"{{ '{{' }}VPN_INTERFACE{{ '}}' }}\",\"random_port\":false,\"upnp\":false}" http://127.0.0.1:5000/api/v2/app/setPreferences 2>&1'
      - VPN_PORT_FORWARDING_DOWN_COMMAND=/bin/sh -c 'wget -O- --retry-connrefused --post-data "json={\"listen_port\":0,\"current_network_interface\":\"lo\"}" http://127.0.0.1:5000/api/v2/app/setPreferences 2>&1'
      - TZ=UTC
      - UPDATER_PERIOD=24h
    volumes:
      - ${CONFIG_DIR}/gluetun:/gluetun
    restart: always
    healthcheck:
      test: ["CMD", "/gluetun-entrypoint", "healthcheck"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - ghostship_net

  sabnzbd:
    image: lscr.io/linuxserver/sabnzbd:latest
    container_name: sabnzbd
    restart: always
    environment:
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
      - TZ=UTC
    volumes:
      - ${CONFIG_DIR}/sabnzbd:/config
      - type: volume
        source: share
        target: /downloads
        volume:
          subpath: Downloads
    network_mode: service:gluetun
    depends_on:
      gluetun:
        condition: service_healthy

  qbittorrent:
    image: lscr.io/linuxserver/qbittorrent:latest
    container_name: qbittorrent
    restart: always
    environment:
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
      - TZ=UTC
      - WEBUI_PORT=5000
      - DOCKER_MODS=ghcr.io/vuetorrent/vuetorrent-lsio-mod:latest
    volumes:
      - ${CONFIG_DIR}/qbittorrent:/config
      - type: volume
        source: share
        target: /downloads
        volume:
          subpath: Downloads
    network_mode: service:gluetun
    depends_on:
      gluetun:
        condition: service_healthy

  rtorrent-flood:
    image: jesec/rtorrent-flood:latest
    container_name: rtorrent-flood
    restart: always
    environment:
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
      - TZ=UTC
      - FLOOD_OPTION_RUNDIR=/data
      - WEBUI_PORT={{ rtorrent_flood_port }}
    volumes:
      - ${CONFIG_DIR}/rtorrent-flood:/config
      - type: volume
        source: share
        target: /downloads
        volume:
          subpath: Downloads
    network_mode: service:gluetun
    depends_on:
      gluetun:
        condition: service_healthy

  plex:
    image: lscr.io/linuxserver/plex:latest
    container_name: plex
    restart: always
    networks:
      - ghostship_net
    ports:
      - 32400:32400
      - 1900:1900/udp
      - 3005:3005
      - 5353:5353/udp
      - 8324:8324
      - 32410:32410/udp
      - 32412:32412/udp
      - 32413:32413/udp
      - 32414:32414/udp
      - 32469:32469
    environment:
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
      - TZ=UTC
      - VERSION=latest
      - PLEX_CLAIM=${PLEX_CLAIM}
    devices:
      - /dev/dri:/dev/dri
    volumes:
      - ${CONFIG_DIR}/plex:/config
      - type: volume
        source: share
        target: /library
        volume:
          subpath: Library

  plex-auto-languages:
    image: remirigal/plex-auto-languages:latest
    container_name: plex-auto-languages
    restart: always
    environment:
      - PLEX_URL=http://plex:32400
      - PLEX_TOKEN=${PLEX_TOKEN}
      - TZ=UTC
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
    volumes:
      - ${CONFIG_DIR}/plex-auto-languages:/config
    networks:
      - ghostship_net

  prowlarr:
    image: lscr.io/linuxserver/prowlarr:latest
    container_name: prowlarr
    restart: always
    environment:
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
      - TZ=UTC
    volumes:
      - ${CONFIG_DIR}/prowlarr:/config
    networks:
      - ghostship_net

  sonarr:
    image: lscr.io/linuxserver/sonarr:latest
    container_name: sonarr
    restart: always
    environment:
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
      - TZ=UTC
    volumes:
      - ${CONFIG_DIR}/sonarr:/config
      - type: volume
        source: share
        target: /downloads
        volume:
          subpath: Downloads
      - type: volume
        source: share
        target: /tv
        volume:
          subpath: Library/TV
    networks:
      - ghostship_net

  radarr:
    image: lscr.io/linuxserver/radarr:latest
    container_name: radarr
    restart: always
    environment:
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
      - TZ=UTC
    volumes:
      - ${CONFIG_DIR}/radarr:/config
      - type: volume
        source: share
        target: /downloads
        volume:
          subpath: Downloads
      - type: volume
        source: share
        target: /movies
        volume:
          subpath: Library/Movies
    networks:
      - ghostship_net

  bazarr:
    image: lscr.io/linuxserver/bazarr:latest
    container_name: bazarr
    restart: always
    environment:
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
      - TZ=UTC
    volumes:
      - ${CONFIG_DIR}/bazarr:/config
      - type: volume
        source: share
        target: /movies
        volume:
          subpath: Library/Movies
      - type: volume
        source: share
        target: /tv
        volume:
          subpath: Library/TV
    networks:
      - ghostship_net

  recyclarr:
    image: ghcr.io/recyclarr/recyclarr:latest
    container_name: recyclarr
    restart: always
    user: "{{ apps_uid }}:{{ apps_gid }}"
    environment:
      - TZ=UTC
      - CRON_SCHEDULE=@daily
    volumes:
      - ${CONFIG_DIR}/recyclarr:/config
    networks:
      - ghostship_net

  huntarr:
    image: ghcr.io/plexguide/huntarr:latest
    container_name: huntarr
    restart: always
    user: "{{ apps_uid }}:{{ apps_gid }}"
    environment:
      - TZ=UTC
    volumes:
      - ${CONFIG_DIR}/huntarr:/config
    networks:
      - ghostship_net

  flaresolverr:
    image: ghcr.io/flaresolverr/flaresolverr:latest
    container_name: flaresolverr
    restart: always
    environment:
      - TZ=UTC
      - LOG_LEVEL=info
    networks:
      - ghostship_net

  tautulli:
    image: lscr.io/linuxserver/tautulli:latest
    container_name: tautulli
    restart: always
    environment:
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
      - TZ=UTC
    volumes:
      - ${CONFIG_DIR}/tautulli:/config
      - ${CONFIG_DIR}/plex/Library/Application Support/Plex Media Server/Logs:/logs:ro
    networks:
      - ghostship_net

  metube:
    image: ghcr.io/alexta69/metube:latest
    container_name: metube
    restart: always
    environment:
      - UID={{ apps_uid }}
      - GID={{ apps_gid }}
    volumes:
      - type: volume
        source: share
        target: /downloads
        volume:
          subpath: Downloads/MeTube
    networks:
      - ghostship_net

  bentopdf:
    image: bentopdf/bentopdf:latest
    container_name: bentopdf
    restart: always
    networks:
      - ghostship_net

  it-tools:
    image: corentinth/it-tools:latest
    container_name: it-tools
    restart: always
    networks:
      - ghostship_net

  romm:
    image: rommapp/romm:latest
    container_name: romm
    restart: always
    user: "{{ apps_uid }}:{{ apps_gid }}"
    environment:
      - DB_HOST=romm-db
      - DB_NAME=romm
      - DB_USER=romm
      - DB_PASSWD=${ROMM_DB_PASSWORD}
      - ROMM_AUTH_SECRET_KEY=${ROMM_AUTH_SECRET}
      - IGDB_CLIENT_ID=${ROMM_IGDB_CLIENT_ID}
      - IGDB_CLIENT_SECRET=${ROMM_IGDB_CLIENT_SECRET}
      - RETROACHIEVEMENTS_API_KEY=${ROMM_RETROACHIEVEMENTS_API_KEY}
      - STEAMGRIDDB_API_KEY=${ROMM_STEAMGRIDDB_API_KEY}
      - SCREENSCRAPER_USER=${ROMM_SCREEN_SCRAPER_USER}
      - SCREENSCRAPER_PASSWORD=${ROMM_SCREEN_SCRAPER_PASS}
      - HASHEOUS_API_ENABLED=true
      - HLTB_API_ENABLED=true
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
    volumes:
      - ${CONFIG_DIR}/romm/resources:/romm/resources
      - ${CONFIG_DIR}/romm/redis-data:/redis-data
      - ${CONFIG_DIR}/romm/config:/romm/config
      - type: volume
        source: share
        target: /romm/library
        volume:
          subpath: Library/ROMs
      - type: volume
        source: share
        target: /romm/assets
        volume:
          subpath: Library/ROMs/.romm
    depends_on:
      romm-db:
        condition: service_healthy
    networks:
      - ghostship_net

  romm-db:
    image: lscr.io/linuxserver/mariadb:latest
    container_name: romm-db
    restart: always
    environment:
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
      - TZ=UTC
      - MYSQL_ROOT_HOST=127.0.0.1
      - MYSQL_ALLOW_EMPTY_PASSWORD=yes
      - MYSQL_DATABASE=romm
      - MYSQL_USER=romm
      - MYSQL_PASSWORD=${ROMM_DB_PASSWORD}
    volumes:
      - ${CONFIG_DIR}/romm-db:/config
    healthcheck:
      test: ["CMD", "mariadb-admin", "ping", "-h", "localhost"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - ghostship_net

  mariadb:
    image: lscr.io/linuxserver/mariadb:latest
    container_name: mariadb
    restart: always
    environment:
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
      - TZ=UTC
    volumes:
      - ${CONFIG_DIR}/mariadb:/config
    healthcheck:
      test: ["CMD", "mariadb-admin", "ping", "-h", "localhost"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - ghostship_net

  fileflows:
    image: revenz/fileflows:latest
    container_name: fileflows
    restart: always
    environment:
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
      - TZ=UTC
    devices:
      - /dev/dri:/dev/dri
    volumes:
      - ${CONFIG_DIR}/fileflows/data:/app/Data
      - ${CONFIG_DIR}/fileflows/logs:/app/Logs
      - ${CONFIG_DIR}/fileflows/temp:/temp
      - type: volume
        source: share
        target: /media
        volume:
          subpath: Library
    networks:
      - ghostship_net

  homeassistant:
    image: lscr.io/linuxserver/homeassistant:latest
    container_name: homeassistant
    restart: always
    environment:
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
      - TZ=UTC
      - DOCKER_MODS=linuxserver/mods:homeassistant-hacs
    volumes:
      - ${CONFIG_DIR}/homeassistant:/config
    networks:
      - ghostship_net

  changedetection:
    image: lscr.io/linuxserver/changedetection.io:latest
    container_name: changedetection
    restart: always
    environment:
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
      - TZ=UTC
      - PLAYWRIGHT_DRIVER_URL=ws://browser-sockpuppet-chrome:3000
    volumes:
      - ${CONFIG_DIR}/changedetection:/config
    networks:
      - ghostship_net
    depends_on:
      - browser-sockpuppet-chrome

  browser-sockpuppet-chrome:
    image: dgtlmoon/sockpuppetbrowser:latest
    container_name: browser-sockpuppet-chrome
    hostname: browser-sockpuppet-chrome
    restart: always
    cap_add:
      - SYS_ADMIN
    environment:
      - SCREEN_WIDTH=1920
      - SCREEN_HEIGHT=1024
      - SCREEN_DEPTH=16
      - MAX_CONCURRENT_CHROME_PROCESSES=10
    networks:
      - ghostship_net

  arcane:
    image: ghcr.io/getarcaneapp/arcane:latest
    container_name: arcane
    restart: always
    environment:
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
      - TZ=UTC
      - APP_URL=http://arcane:3552
      - ENCRYPTION_KEY=${ARCANE_ENCRYPTION_KEY}
      - JWT_SECRET=${ARCANE_JWT_SECRET}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ${CONFIG_DIR}/arcane:/app/data
      - ${INSTALL_DIR}:/app/data/projects
    networks:
      - ghostship_net

  activepieces:
    image: activepieces/activepieces:latest
    container_name: activepieces
    restart: always
    environment:
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
      - TZ=UTC
      - AP_REDIS_TYPE=MEMORY
      - AP_DB_TYPE=SQLITE3
      - AP_FRONTEND_URL=${ACTIVEPIECES_FRONTEND_URL}
    volumes:
      - ${CONFIG_DIR}/activepieces:/root/.activepieces
    networks:
      - ghostship_net

  syncthing:
    image: lscr.io/linuxserver/syncthing:latest
    container_name: syncthing
    restart: always
    environment:
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
      - TZ=UTC
    volumes:
      - ${CONFIG_DIR}/syncthing:/config
      - type: volume
        source: share
        target: /library
        volume:
          subpath: Library
    ports:
      - 8384:8384
      - 22000:22000/tcp
      - 22000:22000/udp
      - 21027:21027/udp
    networks:
      - ghostship_net

  zerobyte:
    image: ghcr.io/nicotsx/zerobyte:latest
    container_name: zerobyte
    restart: always
    cap_add:
      - SYS_ADMIN
    devices:
      - /dev/fuse:/dev/fuse
    environment:
      - TZ=UTC
    volumes:
      - ${CONFIG_DIR}/zerobyte:/var/lib/zerobyte
    networks:
      - ghostship_net

  booklore:
    image: booklore/booklore:latest
    container_name: booklore
    restart: always
    environment:
      - USER_ID={{ apps_uid }}
      - GROUP_ID={{ apps_gid }}
      - TZ=UTC
      - DATABASE_URL=jdbc:mariadb://booklore-db:3306/booklore
      - DATABASE_USERNAME=booklore
      - DATABASE_PASSWORD=${BOOKLORE_DB_PASSWORD}
      - BOOKLORE_PORT=6060
    depends_on:
      booklore-db:
        condition: service_healthy
    volumes:
      - ${CONFIG_DIR}/booklore:/app/data
      - type: volume
        source: share
        target: /books
        volume:
          subpath: Library/Books
      - type: volume
        source: share
        target: /bookdrop
        volume:
          subpath: Library/Books/.bookdrop
    networks:
      - ghostship_net

  booklore-db:
    image: lscr.io/linuxserver/mariadb:latest
    container_name: booklore-db
    restart: always
    environment:
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
      - TZ=UTC
      - MYSQL_ROOT_HOST=127.0.0.1
      - MYSQL_ALLOW_EMPTY_PASSWORD=yes
      - MYSQL_DATABASE=booklore
      - MYSQL_USER=booklore
      - MYSQL_PASSWORD=${BOOKLORE_DB_PASSWORD}
    volumes:
      - ${CONFIG_DIR}/booklore-db:/config
    healthcheck:
      test: ["CMD", "mariadb-admin", "ping", "-h", "localhost"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - ghostship_net

  warracker:
    image: ghcr.io/sassanix/warracker/main:latest
    container_name: warracker
    restart: always
    environment:
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
      - TZ=UTC
      - DB_HOST=warracker-db
      - DB_PORT=5432
      - DB_NAME=warracker
      - DB_USER=warracker
      - DB_PASSWORD=${WARRACKER_DB_PASSWORD}
      - SECRET_KEY=${WARRACKER_SECRET_KEY}
      - WARRACKER_MEMORY_MODE=optimized
      - PYTHONUNBUFFERED=1
    volumes:
      - ${CONFIG_DIR}/warracker/data:/app/data
      - ${CONFIG_DIR}/warracker/uploads:/app/uploads
    depends_on:
      warracker-db:
        condition: service_healthy
    networks:
      - ghostship_net

  warracker-db:
    image: postgres:16-alpine
    container_name: warracker-db
    restart: always
    user: "{{ apps_uid }}:{{ apps_gid }}"
    environment:
      - POSTGRES_DB=warracker
      - POSTGRES_USER=warracker
      - POSTGRES_PASSWORD=${WARRACKER_DB_PASSWORD}
      - POSTGRES_HOST_AUTH_METHOD=trust
      - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      - ${CONFIG_DIR}/warracker-db:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - ghostship_net

  manyfold:
    image: ghcr.io/manyfold3d/manyfold-solo:latest
    container_name: manyfold
    restart: always
    environment:
      - SECRET_KEY_BASE=${MANYFOLD_SECRET_KEY}
      - PUID={{ apps_uid }}
      - PGID={{ apps_gid }}
      - TZ=UTC
    volumes:
      - ${CONFIG_DIR}/manyfold:/config
      - type: volume
        source: share
        target: /models
        volume:
          subpath: Library/3D
    networks:
      - ghostship_net

  convertx:
    image: ghcr.io/c4illin/convertx:latest
    container_name: convertx
    restart: always
    user: "{{ apps_uid }}:{{ apps_gid }}"
    environment:
      - HTTP_ALLOWED=true
      - ACCOUNT_REGISTRATION=false
      - ALLOW_UNAUTHENTICATED=true
      - HIDE_HISTORY=true
    volumes:
      - ${CONFIG_DIR}/convertx:/app/data
    networks:
      - ghostship_net

  homepage:
    image: ghcr.io/gethomepage/homepage:latest
    container_name: homepage
    restart: always
    user: "{{ apps_uid }}:{{ docker_gid }}"
    environment:
      - PUID={{ apps_uid }}
      - PGID={{ docker_gid }}
      - TZ=UTC
      - HOMEPAGE_ALLOWED_HOSTS=*
    volumes:
      - ${CONFIG_DIR}/homepage:/app/config
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - ghostship_net

  docker-autoheal:
    image: willfarrell/autoheal:latest
    container_name: docker-autoheal
    restart: always
    user: "{{ apps_uid }}:{{ docker_gid }}"
    environment:
      - AUTOHEAL_CONTAINER_LABEL=all
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - ghostship_net

  priceghost-db:
    image: postgres:16-alpine
    container_name: priceghost-db
    restart: always
    user: "{{ apps_uid }}:{{ apps_gid }}"
    environment:
      - POSTGRES_DB=priceghost
      - POSTGRES_USER=priceghost
      - POSTGRES_PASSWORD=${PRICEGHOST_DB_PASSWORD}
      - POSTGRES_HOST_AUTH_METHOD=trust
      - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      - ${CONFIG_DIR}/priceghost-db:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - ghostship_net

  priceghost-backend:
    build: ./priceghost-src/backend
    container_name: priceghost-backend
    restart: always
    environment:
      - DATABASE_URL=postgresql://priceghost:${PRICEGHOST_DB_PASSWORD}@priceghost-db:5432/priceghost
      - JWT_SECRET=${PRICEGHOST_JWT_SECRET}
      - PORT=3001
      - NODE_ENV=production
    depends_on:
      priceghost-db:
        condition: service_healthy
    networks:
      ghostship_net:
        aliases:
          - backend

  priceghost:
    build: ./priceghost-src/frontend
    container_name: priceghost
    restart: always
    # This container listens on port 3000 by default.
    depends_on:
      - priceghost-backend
    networks:
      - ghostship_net

networks:
  ghostship_net:
    driver: bridge

volumes:
  share:
    driver: local
    driver_opts:
      type: nfs
      o: "addr=192.168.200.106,rw,nfsvers=4,hard,intr,rsize=8192,wsize=8192"
      device: ":/volume1/share"
